{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d173736-e907-4554-96b6-4032b88db73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: \n",
    "# ollama-python Github\n",
    "# https://github.com/ollama/ollama-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffab06f4-84e7-42c9-b517-6b4ecb2d0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560d195-c00a-4d2a-b3d0-f1a6ba72b8e2",
   "metadata": {},
   "source": [
    "## No Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6f99fc-9003-4aa7-bab2-801724562c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user said \"Hello\". I need to respond appropriately. Since they're just greeting me, I should respond with a friendly greeting. Maybe say \"Hello!\" and ask how I can assist them. Keep it simple and welcoming. No need for any complicated responses. Just a standard greeting and offer of help.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "response: ChatResponse = chat(model='qwen3:4b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Hello',\n",
    "  },\n",
    "])\n",
    "#print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7c64b-10ae-4e0c-bde1-6eee74e83506",
   "metadata": {},
   "source": [
    "## With Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c70557b-9c62-4fd1-a4c0-f5edbb5a7462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user said \"Hello.\" I need to respond in a friendly way. Since my name is Agatha, I should mention that. Maybe add a smiley, but the user said not to use emojis. Wait, the user specified not to use emojis, so I have to avoid them. Let me think of a friendly greeting without any emojis. Maybe \"Hello! I'm Agatha. How can I assist you today?\" That sounds good. It's polite and introduces myself. I should keep it simple and welcoming. Let me check if that meets all the requirements. No emojis, friendly, and introduces my name. Yep, that should work.\n",
      "</think>\n",
      "\n",
      "Hello! I'm Agatha. How can I assist you today?"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "# Add this to the system message to turn off thinking:\n",
    "# /no_think\n",
    "\n",
    "stream = chat(\n",
    "    model='qwen3:4b',\n",
    "    messages=[\n",
    "            {'role': 'system', 'content': 'You are a friendly assistant named Agatha. Dont use emojis.'},\n",
    "            {'role': 'user', 'content': 'Hello.'},\n",
    "            #{'role': 'assistant', 'content': 'Hello. How can I assist you today?'},\n",
    "            #{'role': 'user', 'content': 'Whats your name?'},\n",
    "             ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6465ee7-4355-48c6-92c5-a09c0de94812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1b2ca39-1937-4b7a-aeda-6c9bdd6c7eb9",
   "metadata": {},
   "source": [
    "## Run a chat loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31d404d1-0c72-4682-878f-b67dc210c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to separate the thinking and the response\n",
    "\n",
    "def process_response(text):\n",
    "    \n",
    "    text1 = text.split('</think>')[0]\n",
    "    text2 = text.split('</think>')[1]\n",
    "    \n",
    "    thinking_text = text1 + '</think>'\n",
    "    response_text = text2.strip()\n",
    "\n",
    "    return thinking_text, response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57907ad3-b950-4f73-9777-7f1ed2076a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_message_history(system_message):\n",
    "\n",
    "    message_history = [\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": system_message\n",
    "                        }\n",
    "                    ]\n",
    "\n",
    "    return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caed2aa4-0325-4035-8383-975c3fba53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chat_agent(message_history, model_name):\n",
    "    \n",
    "    stream = chat(\n",
    "        model=model_name,\n",
    "        messages=message_history,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    full_response = \"\"\n",
    "    for chunk in stream:\n",
    "        content = chunk[\"message\"][\"content\"]\n",
    "        print(content, end='', flush=True)\n",
    "\n",
    "        # Assemble the full message\n",
    "        full_response += content\n",
    "\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ea6dd96-4b1c-4bb0-bfa1-99f6a1ce20d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen3:14b\n",
      "\n",
      "==========\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter something (or 'q' to quit):  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "<think>\n",
      "Okay, the user said \"Hi\". I need to respond appropriately. Since it's a greeting, I should reply with a friendly greeting. Maybe \"Hello! How can I assist you today?\" That sounds good. It's polite and opens the door for them to ask for help. I don't see any other context, so keeping it simple and welcoming is best. Let me make sure there's no typo and that the tone is friendly. Yep, that should work.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? ðŸ˜Š\n",
      "==========\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter something (or 'q' to quit):  What is your knowledge cutoff?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "<think>\n",
      "Okay, the user is asking about my knowledge cutoff. I need to make sure I provide an accurate answer. From what I remember, my training data is up to October 2023. But I should double-check that. Let me confirm the exact date. Yes, the cutoff is October 2023. I should mention that my knowledge is current up to that point and that I can't access information after that. Also, it's important to note that I can't browse the internet in real-time. The user might be asking because they want to know if I can provide the latest information. I should reassure them that while I can't access real-time data, I can help with general knowledge up to October 2023. Maybe add a friendly note offering assistance with any questions they have within that timeframe.\n",
      "</think>\n",
      "\n",
      "My knowledge is current up to **October 2023**. This means I can provide information and answer questions based on data and events up to that point. However, I cannot access real-time or post-October 2023 information, nor can I browse the internet for the latest updates. Let me know if you'd like help with anything within my knowledge cutoff! ðŸ˜Š\n",
      "==========\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter something (or 'q' to quit):  Thanks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "<think>\n",
      "Okay, the user just said \"Thanks.\" I need to respond appropriately.\n",
      "\n",
      "First, I should acknowledge their gratitude. Maybe say something like \"You're welcome!\" to be polite.\n",
      "\n",
      "They might be ending the conversation, so offering further help is good. I can ask if they need anything else. \n",
      "\n",
      "Since the previous interaction was about my knowledge cutoff, maybe they're testing if I remember. But since they thanked me, it's probably just a friendly sign-off.\n",
      "\n",
      "I should keep the response friendly and open-ended. Use an emoji to keep the tone positive. \n",
      "\n",
      "Check for any typos or errors. Make sure the response is concise and matches the user's previous messages. \n",
      "\n",
      "Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "You're welcome! ðŸ˜Š If you have any more questions or need help, feel free to ask. Have a great day! ðŸŒŸ\n",
      "==========\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter something (or 'q' to quit):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Exiting the loop. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Prompting the user for input\n",
    "#user_input = input(\"Please enter something: \")\n",
    "\n",
    "MODEL_NAME = 'qwen3:14b'\n",
    "print(MODEL_NAME)\n",
    "\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "message_history = initialize_message_history(system_message)\n",
    "\n",
    "while True:\n",
    "\n",
    "    print()\n",
    "    print(\"==========\")\n",
    "    user_input = input(\"Enter something (or 'q' to quit): \")\n",
    "    print(\"==========\")\n",
    "\n",
    "    if user_input.lower() == 'q':\n",
    "        print(\"Exiting the loop. Goodbye!\")\n",
    "        break  # Exit the loop\n",
    "\n",
    "    # Update message history\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    message_history.append(message)\n",
    "\n",
    "    # Prompt the chat_agent\n",
    "    llm_response = run_chat_agent(message_history, MODEL_NAME)\n",
    "\n",
    "    # Separate the response and the thinking\n",
    "    thinking_text, response_text = process_response(llm_response)\n",
    "\n",
    "    # Update message history\n",
    "    message = {\"role\": \"assistant\", \"content\": response_text}\n",
    "    message_history.append(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e432a-aba7-4f0b-bfc1-34f40e679d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2599e1-5bff-476e-8654-f0b8dd3c9147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2329826-4bbd-49d3-a979-5d861852c9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b2520-e892-4263-9933-aca8437db0d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304543c-70d0-41bd-9c76-fe21b84fa7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8970c1-7431-4a5c-bfbe-ed4407b326f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ed24f-13f4-4c45-b038-400fe8458353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36b86b-cdb2-4204-9170-c5bdd8166c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
